{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.4 - Concentric sampled deformation gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['text.usetex'] = True\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "\n",
    "from src.models import CustomFFNN, InvariantsICNN\n",
    "from src.data_import import load_train_test_concentric\n",
    "from src.plots import plot_stress_predictions, plot_energy_prediction, plot_loss, plot_stress_currelation\n",
    "from src.analytic_potential import get_C_features\n",
    "from src.predict_utils import predict_multi_cases_PANN, predict_multi_cases_naive\n",
    "from src.utils import get_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration paths\n",
    "data_dir = os.path.abspath('concentric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reached_good_prediction(labels: dict[str, np.ndarray], predictions: dict[str, np.ndarray], threshold: float = 1.0) -> bool:\n",
    "    wmae = get_scores(labels, predictions, 'rmse', use_total=True)\n",
    "    print(f'Weighted MAE: {max(list(wmae.values()))}')\n",
    "    return all(abs(val < threshold) for val in wmae.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive NN calibration on stress $P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_model(train_F: tf.Tensor, train_P: tf.Tensor) -> CustomFFNN:\n",
    "    naive_features = get_C_features(train_F)\n",
    "    naive_labels = tf.reshape(train_P, (-1, 9))\n",
    "\n",
    "    naive_model = CustomFFNN(\n",
    "        hidden_sizes=[32, 32, 32, 9],\n",
    "        activations=['softplus', 'softplus', 'softplus', 'linear']\n",
    "    )\n",
    "    naive_model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "        loss=losses.MeanSquaredError()\n",
    "    )\n",
    "    naive_h = naive_model.fit(naive_features, naive_labels, batch_size=16, epochs=1000, verbose=0)\n",
    "    naive_loss = naive_h.history['loss']\n",
    "    plot_loss(naive_loss)\n",
    "    return naive_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot_naive_model(naive_model: CustomFFNN, examples_FPW_tup: dict[str, tuple[tf.Tensor, tf.Tensor, tf.Tensor]]):\n",
    "    P_naive_test_labels, P_naive_test_preds = predict_multi_cases_naive(naive_model, examples_FPW_tup)\n",
    "    plot_stress_predictions(P_naive_test_labels, P_naive_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_correlate_naive_model(\n",
    "        naive_model: CustomFFNN, \n",
    "        examples_FPW_tup: dict[str, tuple[tf.Tensor, tf.Tensor, tf.Tensor]]\n",
    ") -> bool:\n",
    "    P_naive_test_labels, P_naive_test_preds = predict_multi_cases_naive(naive_model, examples_FPW_tup)\n",
    "    can_predict = reached_good_prediction(P_naive_test_labels, P_naive_test_preds)\n",
    "    if can_predict:\n",
    "        plot_stress_currelation(P_naive_test_labels, P_naive_test_preds)\n",
    "    return can_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PANN calibration on stress $P$ and energy $W$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pann_model(train_F: tf.Tensor, train_P: tf.Tensor, train_W: tf.Tensor) -> InvariantsICNN:\n",
    "    pann_features = train_F\n",
    "    pann_labels = (train_W, train_P)\n",
    "\n",
    "    pann_model = InvariantsICNN(\n",
    "        hidden_sizes=[16, 1],\n",
    "        activations=['softplus', 'linear'],\n",
    "        use_output_and_derivative=True\n",
    "    )\n",
    "    pann_model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.01),\n",
    "        loss=losses.MeanSquaredError()\n",
    "    )\n",
    "    pann_h = pann_model.fit(pann_features, pann_labels, batch_size=32, epochs=1000, verbose=0)\n",
    "    pann_loss = pann_h.history['loss']\n",
    "    plot_loss(pann_loss)\n",
    "    return pann_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot_pann_model(pann_model: InvariantsICNN, examples_FPW_tup: dict[str, tuple[tf.Tensor, tf.Tensor, tf.Tensor]]):\n",
    "    (\n",
    "        P_pann_test_labels, W_pann_test_labels, P_pann_test_preds, W_pann_test_preds\n",
    "    ) = predict_multi_cases_PANN(pann_model, examples_FPW_tup)\n",
    "    plot_stress_predictions(P_pann_test_labels, P_pann_test_preds)\n",
    "    plot_energy_prediction(W_pann_test_labels, W_pann_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_correlate_pann_model(\n",
    "        pann_model: InvariantsICNN, \n",
    "        examples_FPW_tup: dict[str, tuple[tf.Tensor, tf.Tensor, tf.Tensor]]\n",
    ") -> bool:\n",
    "    (P_pann_test_labels, _, P_pann_test_preds, _) = predict_multi_cases_PANN(pann_model, examples_FPW_tup)\n",
    "    can_predict = reached_good_prediction(P_pann_test_labels, P_pann_test_preds) \n",
    "    if can_predict:\n",
    "        plot_stress_currelation(P_pann_test_labels, P_pann_test_preds)\n",
    "    return can_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets, calibrate and predict both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_size in [0.9, 0.75, 0.6, 0.5, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1]:\n",
    "    print('=' * 100)\n",
    "    print(f'Test size of {test_size*100}%')\n",
    "    train_data, test_data = load_train_test_concentric(data_dir, test_size=test_size)\n",
    "\n",
    "    train_F = tf.concat([tup[0] for tup in train_data.values()], axis=0)\n",
    "    train_P = tf.concat([tup[1] for tup in train_data.values()], axis=0)\n",
    "    train_W = tf.concat([tup[2] for tup in train_data.values()], axis=0)\n",
    "\n",
    "    naive_model = train_naive_model(train_F, train_P)\n",
    "    can_naive_pred = predict_and_correlate_naive_model(naive_model, test_data)\n",
    "\n",
    "    pann_model = train_pann_model(train_F, train_P, train_W)\n",
    "    can_pann_pred = predict_and_correlate_pann_model(pann_model, test_data)\n",
    "\n",
    "    rand_examples = np.random.choice(list(test_data.keys()), size=6)\n",
    "    example_test_FPW_tup = {f'Example {idx}': test_data[idx] for idx in rand_examples}\n",
    "    predict_and_plot_pann_model(pann_model, example_test_FPW_tup)\n",
    "    predict_and_plot_naive_model(naive_model, example_test_FPW_tup)\n",
    "\n",
    "    if can_naive_pred and can_pann_pred:\n",
    "        print(f'Able to predict with a test size of {test_size}')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forl_kernel",
   "language": "python",
   "name": "forl_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
